{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Vision API\n",
    "\n",
    "This notebook applies the google vision API to Iens restaurant pictures to detect what food is on it. The notebook consists of 3 sections:\n",
    "\n",
    "1. An example of calling the vision API for a single image (for in the blog)\n",
    "2. Doing a batch query for all images of all restaurants and uploading the result to BigQuery\n",
    "3. Querying the results / Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_gbq as gbq \n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_colwidth', 250) # Show all columns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project specifics\n",
    "PRIVATE_KEY = '../google-credentials/gsdk-credentials.json'\n",
    "PROJECT_ID = json.load(open(PRIVATE_KEY))['project_id']\n",
    "APIKEY = open('../google-credentials/gc-API-key.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset specifics\n",
    "city = 'amsterdam'\n",
    "date = '20180124'\n",
    "bq_table = '_'.join(['iens.iens', city, date])  # use iens.iens_comments when querying on the comments table\n",
    "bq_table_out = '_'.join(['iens.iens_images', city, date])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# select all info fields, plus image_urls\n",
    "query = \"SELECT info.id, info.name, image_urls FROM {} WHERE info.nr_images > 0\".format(bq_table)\n",
    "\n",
    "df = gbq.read_gbq(query, project_id=PROJECT_ID, private_key=PRIVATE_KEY)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Calling the vision API "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First practice - just run a single request. See if it works!\n",
    "\n",
    "Usefull documentation: \n",
    "* https://developers.google.com/api-client-library/python/start/get_started\n",
    "* https://github.com/GoogleCloudPlatform/cloud-vision/tree/master/python/text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "service = build('vision', 'v1', developerKey=APIKEY)\n",
    "collection = service.images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single request for Blog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_request(url):\n",
    "    return {'image': {'source': {'imageUri': url}},\n",
    "            'features': [{\n",
    "                'type': 'LABEL_DETECTION',\n",
    "                'maxResults': 10}]}\n",
    "\n",
    "def execute_request(url):\n",
    "    return collection.annotate(body={'requests': make_request(url)}).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burger_url = 'https://www.okokorecepten.nl/i/recepten/kookboeken/2014/jamies-comfort-food/jamie-oliver-hamburger-500.jpg'\n",
    "result = execute_request(burger_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "display(Image(burger_url))\n",
    "display(pd.DataFrame(result['responses'][0]['labelAnnotations']).drop('mid', axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set up batch request for all restaurants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know it works for a single image, extrapolate the query to do batch requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch_request(url_list):\n",
    "    return collection.annotate(body={'requests' : [make_request(url) for url in url_list]})\n",
    "\n",
    "def execute_batch_request(url_list, num_retries=1):\n",
    "    return make_batch_request(url_list).execute(num_retries=num_retries)['responses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = {'burger' : 'https://u.tfstatic.com/restaurant_photos/811/352811/169/612/barasti-killer-burger-b42ea.jpg',\n",
    "            'steak' : 'https://u.tfstatic.com/restaurant_photos/811/352811/169/612/barasti-ribstuk-2c5f9.jpg'}\n",
    "\n",
    "# execute with\n",
    "# execute_batch_request(examples.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we want eventually is a dictionary with the following structure, to upload into Google BigQuery:\n",
    "\n",
    "* restaurant id = integer\n",
    "* images = list of dicts:\n",
    "    * image url = string\n",
    "    * labelAnnotation = list of dicts:\n",
    "        - description\n",
    "        - mid\n",
    "        - score\n",
    "        - topicality\n",
    "        \n",
    "Note that Google allows max 16 images per request: https://cloud.google.com/vision/quotas. As there is not many restaurants with that many photo's let's just aggregate by restaurant for each batch and limit it to 16 images in case it does happen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to Series for batch request per restaurant\n",
    "restaurant_image_list = df.groupby(['info_id'])['image_urls'].apply(lambda x: list(x)[0:16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A problem that we encounter while calling the API is that some URLs can be unaccessible for the API leading to error responses. We could build a loop of some sort (with a time-out delay between each repitition), to keep trying a specific URL untill it succeeds. However, as it happens roughly for 10% of all our images, we choose to simply ignore this problem for now and don't return anything for the specific URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_images(image_url, label_annotations):\n",
    "    try: \n",
    "        return {\n",
    "            'image_url' : image_url,\n",
    "            'label_annotations' : label_annotations['labelAnnotations']\n",
    "        }\n",
    "    except KeyError:\n",
    "        # don't return label_annotations if not found\n",
    "        return {\n",
    "            'image_url' : image_url\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `num_retries` parameter in the `execute()` method doesn't solve our problem. It simply repeats the call, but doesn't automatically save all succesfull responses a better final response for the batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run it! *(This may take a while..)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "printcounter = 0\n",
    "for restaurant_id, image_urls in restaurant_image_list.iteritems():\n",
    "    # do batch request\n",
    "    responses = execute_batch_request(image_urls)\n",
    "    # create images object for one restaurant\n",
    "    images = [\n",
    "        parse_images(image_url, label_annotations)\n",
    "        for image_url, label_annotations in \n",
    "        zip(image_urls, responses)\n",
    "    ]\n",
    "    # add results for one restaurant to list\n",
    "    result.append({'info_id' : restaurant_id, 'images' : images})\n",
    "    if (printcounter % 100 == 0):\n",
    "        print('Finished restaurant', printcounter, '/', len(restaurant_image_list))\n",
    "    printcounter += 1\n",
    "    \n",
    "len(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write to jsonlines\n",
    "\n",
    "To upload to BigQuery save as jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('../iens_scraper/output/' + bq_table_out + '.jsonlines', 'w')\n",
    "for item in result:\n",
    "    file.write('%s\\n' % item)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### upload to BigQuery\n",
    "\n",
    "Would be nicer to do this directly from python. For example with `gbq.to_gbq` (which is for dataframes only)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!bq load --autodetect --replace --source_format=NEWLINE_DELIMITED_JSON \\\n",
    "        {bq_table_out} ../iens_scraper/output/{bq_table_out}.jsonlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Query images\n",
    "\n",
    "For example getting the top 15 most found labels by the vision API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT images.label_annotations.description, COUNT(*) AS count \n",
    "FROM {} \n",
    "GROUP BY images.label_annotations.description \n",
    "ORDER BY count DESC\n",
    "LIMIT 15;\n",
    "\"\"\".format(bq_table_out)\n",
    "\n",
    "query_result = gbq.read_gbq(query, project_id=PROJECT_ID, private_key=PRIVATE_KEY)\n",
    "query_result.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or.. getting the max score for each hamburger image per restaurant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "keywords = ('hamburger', 'cheeseburger', 'veggie burger', 'slider') \n",
    "query = \"\"\"\n",
    "SELECT\n",
    "  info_id, images.image_url, images.label_annotations.score, images.label_annotations.description\n",
    "FROM (\n",
    "  SELECT \n",
    "      *,\n",
    "      ROW_NUMBER() OVER(PARTITION BY info_id ORDER BY images.image_url DESC, images.label_annotations.score DESC) AS highest_score\n",
    "  FROM {}\n",
    "  WHERE images.label_annotations.description IN {}\n",
    ")\n",
    "WHERE highest_score = 1\n",
    "ORDER BY images.label_annotations.score DESC\n",
    "\"\"\".format(bq_table_out, keywords)\n",
    "\n",
    "query_result = gbq.read_gbq(query, project_id=PROJECT_ID, private_key=PRIVATE_KEY)\n",
    "query_result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the distribution of returned scores, we see that most have a confidence above 80%. Question is: which threshold score do we pick for claiming that there is indeed a burger on the picture?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_result['images_label_annotations_score'].hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining some random cases from bottom up, we find that the threshold for good burger classification seems to lie around a score of 75%. Also we note that the descriptions 'veggie burger' and 'slider' might not be really what we are looking for. \n",
    "\n",
    "**Conclusion:** Use a score of 75% and up, and description hamburger for determining if a restaurant has them or not!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write restaurants with hamburger ids to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_result['info_id'].to_csv('../iens_scraper/output/image_tags.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
