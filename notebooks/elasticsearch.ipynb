{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text analysis of restaurant reviews\n",
    "## Find hamburgers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we analyze the restaurant reviews for a city and a specific date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "%matplotlib inline\n",
    "\n",
    "# hide warnings. `gbq.read_gbq()` gives some\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "sys.path.append('../scrape_save_search')\n",
    "import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data.load_comments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run Elasticsearch as a service:\n",
    "+ `brew tap homebrew/services`\n",
    "+ `brew services start elasticsearch`\n",
    "\n",
    "You can check that it's up-and-running by examining the logs:\n",
    "+ `tail -n 15 /usr/local/var/log/elasticsearch.log`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "es = Elasticsearch([{'host': 'localhost', 'port': 9200}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if it is running\n",
    "es.ping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check its health\n",
    "print(es.cat.health(v=True, \n",
    "                    h=['timestamp', 'cluster', 'status', 'node.total']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete old index if it exists\n",
    "es.indices.delete(index='restaurant_comments', ignore=404)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new index\n",
    "es.indices.create(index='restaurant_comments', ignore=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pre-processing and analyzer\n",
    "hyphens_and_apostrophes_strip = {\n",
    "    \"hyphens_and_apostrophes_strip\": {\n",
    "        \"type\": \"mapping\",\n",
    "        \"mappings\": [ \n",
    "            \"- => ' '\",\n",
    "            \"' => \"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "dutch_stop = {\n",
    "    \"dutch_stop\": {\n",
    "        \"type\": \"stop\",\n",
    "        \"stopwords\": \"_dutch_\"\n",
    "    }\n",
    "}\n",
    "\n",
    "ngram_tokenizer = {\n",
    "    \"ngram_tokenizer\": {\n",
    "        \"type\": \"ngram\",\n",
    "        \"min_gram\": 3,\n",
    "        \"max_gram\": 4\n",
    "    }\n",
    "}\n",
    "\n",
    "analyzer = {\n",
    "    \"restaurant_comments_analyzer\": {\n",
    "        \"type\": \"custom\",\n",
    "        \"char_filter\": [\"hyphens_and_apostrophes_strip\"],\n",
    "        \"tokenizer\": \"ngram_tokenizer\", #\"standard\",\n",
    "        \"filter\": [\"lowercase\", \"dutch_stop\", \"asciifolding\"]\n",
    "    }\n",
    "}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply these on our index \n",
    "es.indices.close(index='restaurant_comments')\n",
    "es.indices.put_settings(\n",
    "    index='restaurant_comments', \n",
    "    body={\n",
    "        \"analysis\": {\n",
    "            \"char_filter\": hyphens_and_apostrophes_strip,\n",
    "            \"tokenizer\": ngram_tokenizer,\n",
    "            \"filter\": dutch_stop,\n",
    "            \"analyzer\": analyzer\n",
    "        }\n",
    "    }\n",
    ")\n",
    "es.indices.open(index='restaurant_comments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define what our data looks like\n",
    "es.indices.put_mapping(\n",
    "    index='restaurant_comments',\n",
    "    update_all_types=True,\n",
    "    doc_type='restaurant_review',\n",
    "    body={\n",
    "        \"properties\": {\n",
    "            \"comment\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"restaurant_comments_analyzer\"\n",
    "            },\n",
    "            \"name\": {\n",
    "                \"type\": \"keyword\"            \n",
    "            },\n",
    "            \"id\": {\n",
    "                \"type\": \"text\"\n",
    "            },\n",
    "            \"rating\": {\n",
    "                \"type\": \"integer\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all comments to our index\n",
    "from elasticsearch.helpers import parallel_bulk\n",
    "def generate_actions(df):    \n",
    "    for _, row in df.iterrows():\n",
    "        src = {\n",
    "            'comment': row['comment'],\n",
    "            'name': row['name'],\n",
    "            'id': str(row['id']),\n",
    "            'rating': int(row['rating_food'])  \n",
    "        }\n",
    "        yield {\n",
    "            '_op_type': 'index',\n",
    "            '_source': src \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for success, info in parallel_bulk(\n",
    "    client=es, \n",
    "    actions=generate_actions(df),\n",
    "    index='restaurant_comments', \n",
    "    doc_type='restaurant_review',\n",
    "    thread_count=4):\n",
    "    if not success: print('Document insertion failed', info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Search for 'burger'\n",
    "res = es.search(\n",
    "    index='restaurant_comments', \n",
    "    doc_type='restaurant_review',\n",
    "    body={\n",
    "        \"size\": 10000,\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"comment\": \"burger\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show top results\n",
    "for i, document in enumerate(res['hits']['hits']):\n",
    "    print('Score: ', document['_score'])\n",
    "    pprint(document['_source'], indent=2)\n",
    "    if i == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract info\n",
    "result = pd.DataFrame(\n",
    "    [{**x['_source'], 'score': x['_score']} for x in res['hits']['hits']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Aggregate per restaurant\n",
    "restaurant_scores = (\n",
    "    result\n",
    "    .groupby('id')['score']\n",
    "    .max()\n",
    "    .sort_values()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution\n",
    "ax = sns.distplot(restaurant_scores)\n",
    "ax.set_xlabel('Restaurant scores (higher is better)', fontsize=13)\n",
    "ax.set_ylabel('Number of restaurants', fontsize=13)\n",
    "ax.set_title('Number of restaurants per score', fontsize=14)\n",
    "ax.set_yticks([]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select burger restaurants\n",
    "burger_restaurants = (\n",
    "    restaurant_scores\n",
    "    .loc[lambda r: r > 20]\n",
    "    .reset_index()\n",
    "    ['id']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "burger_restaurants.to_csv('elasticsearch_burger_tags.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
